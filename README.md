# ğŸ™ï¸ AI Enabled Real-Time Sales Call Assistant

**Project Title:** AI Enabled Real Time AI Sales Call Assistant for Enhanced Conversation Strategies  
**Domain:** Artificial Intelligence / Machine Learning / NLP  
**Internship:** Infosys Springboard (Capstone Project)

---

## ğŸ“ Project Overview
This project is a high-performance **Real-Time AI Assistant** designed for sales professionals. It listens to live customer calls, transcribes the conversation, and uses Large Language Models (LLMs) to provide instant feedback on customer sentiment and intent. 

The goal is to empower sales representatives with "AI-driven empathy" and conversation strategies to improve customer satisfaction and conversion rates.

---

## âœ¨ Key Features
* **Live Transcription:** Converts speech to text with high accuracy using **OpenAI's Whisper**.
* **Intent Recognition:** Automatically identifies if the customer is inquiring, complaining, or greeting.
* **Sentiment Analysis:** Detects the emotional tone (Positive, Negative, Neutral) of the speaker.
* **Smart Coaching Tips:** Displays real-time sales advice (e.g., "Acknowledge & Empathize") based on the conversation flow.
* **Distributed Architecture:** Uses a **FastAPI** backend to handle complex AI computations independently from the frontend.



---

## ğŸ› ï¸ Tech Stack
* **Frontend:** Streamlit (For the Interactive Dashboard)
* **Backend:** FastAPI (For High-performance API handling)
* **Speech-to-Text:** Faster-Whisper (Open-source STT)
* **LLM Engine:** TinyLlama (via Ollama)
* **Communication:** REST API, Pydantic, JSON
* **Audio Processing:** SoundDevice, SoundFile

---

## ğŸ“‚ Repository Structure
```text
â”œâ”€â”€ app.py              # Streamlit Web Application (UI)
â”œâ”€â”€ server_api.py       # FastAPI Server (AI Logic & Inference)
â”œâ”€â”€ test.py             # Script to verify backend connectivity
â”œâ”€â”€ requirements.txt    # List of dependencies
â””â”€â”€ README.md           # Project Documentation
```
---
## âš™ï¸ How it Works
**Audio Input**: The salesperson speaks into the microphone via the Streamlit interface.
**Processing**: The audio file is sent to the FastAPI server.
**Inference:**
- Whisper model transcribes the audio into text.
- TinyLlama analyzes the text to determine the Intent and Sentiment.
- Feedback: The server sends back a JSON response containing the analysis and a custom sales tip.
- UI Update: Results are displayed instantly on the dashboard.
